{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309a142e-a7c4-40ed-801b-0dafb5963ce0",
   "metadata": {},
   "source": [
    "# Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc404318-31c0-475a-88ea-3e4fc575a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Import packages\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Helper functions\n",
    "# =============================================================================\n",
    "\n",
    "def plot_initial_conditions(x_space, t_time, k_initial, q_entry, q_exit):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(4, 9))\n",
    "    ax1.plot(x_space, k_initial)\n",
    "    ax1.set_title(\"Initial Density\", fontsize=14)\n",
    "    ax1.set_xlabel(\"Space $x$ [m]\", fontsize=12)\n",
    "    ax1.set_ylabel(r\"$\\rho$ ($x,0$) [vehs/km]\", fontsize=12)\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2.plot(t_time, q_entry)\n",
    "    ax2.set_title(\"Entering Boundary Flow\", fontsize=14)\n",
    "    ax2.set_xlabel(\"Time $t$ [s]\", fontsize=12)\n",
    "    ax2.set_ylabel(r\"$q$ ($x_{\\rm enter},t$) [vehs/hr]\", fontsize=12)\n",
    "    ax2.grid()\n",
    "\n",
    "    ax3.plot(t_time, q_exit)\n",
    "    ax3.set_title(\"Exiting Boundary Flow\", fontsize=14)\n",
    "    ax3.set_xlabel(\"Time $t$ [s]\", fontsize=12)\n",
    "    ax3.set_ylabel(r\"$q$ ($x_{\\rm exit},t$) [vehs/hr]\", fontsize=12)\n",
    "    ax3.grid()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, (ax1, ax2, ax3)\n",
    "\n",
    "# =============================================================================\n",
    "# Godunov Scheme\n",
    "# =============================================================================\n",
    "\n",
    "def compute_psi(rho, x_grid):\n",
    "    # Avoid division by zero if any rho=1 by clipping slightly\n",
    "    eps = 1e-8\n",
    "    rho_clipped = np.minimum(rho, 1 - eps)\n",
    "\n",
    "    inv_1_minus_rho = 1 / (1 - rho_clipped)\n",
    "\n",
    "    # Grid spacing\n",
    "    dx = x_grid[1] - x_grid[0]\n",
    "\n",
    "    # Cumulative sums from left and from right\n",
    "    cumsum_left = np.cumsum(inv_1_minus_rho) * dx\n",
    "    cumsum_right = np.cumsum(inv_1_minus_rho[::-1]) * dx\n",
    "    cumsum_right = cumsum_right[::-1]\n",
    "\n",
    "    # Find index where difference is minimal\n",
    "    min_diff_index = np.argmin(np.abs(cumsum_left - cumsum_right))\n",
    "    psi = x_grid[min_diff_index]\n",
    "    return psi\n",
    "\n",
    "\n",
    "\n",
    "def fundamental_diag(k, k_max, v_max, k_cr, fd):\n",
    "    return k*v_max*(1-k/k_max)\n",
    "\n",
    "\n",
    "def Demandfn(k, k_max, v_max, k_cr, q_max, fd):\n",
    "    if k <= k_cr:\n",
    "        q = k*v_max*(1-k/k_max)\n",
    "    else:\n",
    "        q = q_max\n",
    "    return q\n",
    "\n",
    "\n",
    "def InvDemandfn_num(q, dem_fn, k_arr):\n",
    "    qb = dem_fn[dem_fn < q][-1]\n",
    "    qa = dem_fn[dem_fn >= q][0]\n",
    "    kb = k_arr[dem_fn < q][-1]\n",
    "    ka = k_arr[dem_fn >= q][0]\n",
    "    k = kb + (ka-kb)*(q-qb)/(qa-qb)\n",
    "    return k\n",
    "\n",
    "\n",
    "def InvDemandfn(q, k_max, v_max, k_cr, q_max, v_free, fd):\n",
    "    q = min(q, q_max)\n",
    "    k = (k_max-np.sqrt(k_max**2-4*k_max/v_free*q))/2\n",
    "    return k\n",
    "\n",
    "\n",
    "def Supplyfn(k, k_max, v_max, k_cr, q_max, fd):\n",
    "    if k >= k_cr:\n",
    "        q = k*v_max*(1-k/k_max)\n",
    "    else:\n",
    "        q = q_max\n",
    "    return q\n",
    "\n",
    "\n",
    "def InvSupplyfn_num(q, sup_fn, k_arr):\n",
    "    qb = sup_fn[sup_fn <= q][0]\n",
    "    qa = sup_fn[sup_fn > q][-1]\n",
    "    kb = k_arr[sup_fn <= q][0]\n",
    "    ka = k_arr[sup_fn > q][-1]\n",
    "    k = kb + (ka-kb)*(q-qb)/(qa-qb)\n",
    "    return k\n",
    "\n",
    "\n",
    "def InvSupplyfn(q, k_max, v_max, k_cr, q_max, v_free, fd):\n",
    "    q = min(q, q_max)\n",
    "    k = (k_max+np.sqrt(k_max**2-4*k_max/v_free*q))/2\n",
    "    return k\n",
    "\n",
    "\n",
    "def bound_cond_entry(k_prev, q_en, k_max, v_max, k_cr, q_max, v_free, fd):\n",
    "    q_en = min(q_en, q_max)\n",
    "    supply = Supplyfn(k_prev, k_max, v_max, k_cr, q_max, fd)\n",
    "    if q_en <= supply:\n",
    "        k = InvDemandfn(q_en, k_max, v_max, k_cr, q_max, v_free, fd)\n",
    "    else:\n",
    "        k = InvSupplyfn(q_en, k_max, v_max, k_cr, q_max, v_free, fd)\n",
    "    return k\n",
    "\n",
    "\n",
    "def bound_cond_exit(k_prev, q_ex, k_max, v_max, k_cr, q_max, v_free, fd):\n",
    "    q_ex = min(q_ex, q_max)\n",
    "    demand = Demandfn(k_prev, k_max, v_max, k_cr, q_max, fd)\n",
    "    if q_ex < demand:\n",
    "        k = InvSupplyfn(q_ex, k_max, v_max, k_cr, q_max, v_free, fd)\n",
    "    else:\n",
    "        k = InvDemandfn(q_ex, k_max, v_max, k_cr, q_max, v_free, fd)\n",
    "    return k\n",
    "\n",
    "\n",
    "def flux_function(k_xup, k_xdn, k_cr, q_max, k_max, v_max, fd):\n",
    "    if (k_xdn <= k_cr) and (k_xup <= k_cr):\n",
    "        q_star = fundamental_diag(k_xup, k_max, v_max, k_cr, fd)\n",
    "    elif (k_xdn <= k_cr) and (k_xup > k_cr):\n",
    "        q_star = q_max\n",
    "    elif (k_xdn > k_cr) and (k_xup <= k_cr):\n",
    "        q_star = min(fundamental_diag(k_xdn, k_max, v_max, k_cr, fd),\n",
    "                     fundamental_diag(k_xup, k_max, v_max, k_cr, fd))\n",
    "    elif (k_xdn > k_cr) and (k_xup > k_cr):\n",
    "        q_star = fundamental_diag(k_xdn, k_max, v_max, k_cr, fd)\n",
    "    return q_star\n",
    "\n",
    "\n",
    "def density_update(k_x, k_xup, k_xdn, delt, delx, k_cr, q_max, k_max, v_max, fd):\n",
    "    q_in = flux_function(k_xup, k_x, k_cr, q_max, k_max, v_max, fd)\n",
    "    q_out = flux_function(k_x, k_xdn, k_cr, q_max, k_max, v_max, fd)\n",
    "    k_x_nextt = k_x + (delt/delx)*(q_in - q_out)\n",
    "    return k_x_nextt, q_out\n",
    "\n",
    "\n",
    "def CFL_condition(delx, v_max):\n",
    "    max_delt = delx/v_max\n",
    "    return np.around(max_delt, 6)\n",
    "\n",
    "def solver_left(x_left, K_left, q_entry, q_exit, delt, delx, fd_type, t, k_jam, v_free):          \n",
    "    for x in reversed(x_left[0]):\n",
    "        q_max = k_jam*v_free/4\n",
    "        k_cr = k_jam/2\n",
    "        \n",
    "        # Get computational stencil\n",
    "        k_x = K_left[t-1, x]\n",
    "\n",
    "        # start \n",
    "        if x == x_left[0][-1]:\n",
    "            q_en = q_entry[t]\n",
    "            k_xup = 0\n",
    "        else:\n",
    "            k_xup = K_left[t-1, x+1]\n",
    "\n",
    "        # exit\n",
    "        if x == x_left[0][0]:\n",
    "            q_ex = q_exit[t]\n",
    "            k_xdn = 0\n",
    "        else:\n",
    "            k_xdn = K_left[t-1, x-1]\n",
    "\n",
    "        # Calculated and update new density\n",
    "        k_x_next, q_out = density_update(k_x, k_xup, k_xdn, delt, delx, k_cr, q_max, k_jam, v_free, fd_type)\n",
    "        K_left[t, x] = k_x_next\n",
    "    return K_left\n",
    "\n",
    "def solver_right(x_right, K_right, q_entry, q_exit, delt, delx, fd_type, t, k_jam, v_free):\n",
    "    for x in range(len(x_right[0])):\n",
    "        q_max = k_jam*v_free/4\n",
    "        k_cr = k_jam/2\n",
    "\n",
    "        # Get computational stencil\n",
    "        k_x = K_right[t-1, x]\n",
    "        # Start \n",
    "        if x == 0:\n",
    "            q_en = q_entry[t]\n",
    "            k_xup = 0\n",
    "        else:\n",
    "            k_xup = K_right[t-1, x-1]\n",
    "\n",
    "        # Exit\n",
    "        if x == len(x_right[0])-1:\n",
    "            q_ex = q_exit[t]\n",
    "            k_xdn = 0\n",
    "        else:\n",
    "            k_xdn = K_right[t-1, x+1]\n",
    "\n",
    "        # Calculated and update new density\n",
    "        k_x_next, q_out = density_update(k_x, k_xup, k_xdn, delt, delx, k_cr, q_max, k_jam, v_free, fd_type)\n",
    "        K_right[t, x] = k_x_next\n",
    "    return K_right\n",
    "\n",
    "def simulation(k_initial, q_entry, q_exit,\n",
    "                   t_nums, x_nums, delt, delx, fd_params, k_jam_space):\n",
    "    # FD parameters\n",
    "    v_free = fd_params[\"v_free\"]\n",
    "    k_jam = fd_params[\"k_jam\"]\n",
    "    fd_type = fd_params[\"fd_type\"]\n",
    "\n",
    "    store_tp = []\n",
    "\n",
    "    # Initialize time-space indices\n",
    "    x_ind = np.arange(0, x_nums)\n",
    "    t_ind = np.arange(0, t_nums)\n",
    "    X_ind, T_ind = np.meshgrid(x_ind, t_ind)\n",
    "\n",
    "    # Initialize K, Q matrix\n",
    "    K = np.zeros((t_nums, x_nums))\n",
    "    Q = np.zeros((t_nums, x_nums))\n",
    "\n",
    "    K[0, :] = k_initial    # at t = 0\n",
    "\n",
    "    turning_point = compute_psi(K[0, :],x_ind)\n",
    "\n",
    "    x_left = np.where(x_ind <= turning_point)\n",
    "    x_right = np.where(x_ind > turning_point)\n",
    "\n",
    "    K_left = K[:, x_left[0]]\n",
    "    K_right = K[:, x_right[0]]\n",
    "\n",
    "    for t in range(1, X_ind.shape[0]):\n",
    "\n",
    "        store_tp.append(turning_point)\n",
    "\n",
    "        if(turning_point == x_ind[0]):\n",
    "            K = solver_right([x_ind], K, q_entry, q_exit, delt, delx, fd_type, t, k_jam, v_free)\n",
    "        elif(turning_point == x_ind[-1]):\n",
    "            K = solver_left([x_ind], K, q_entry, q_exit, delt, delx, fd_type, t, k_jam, v_free)\n",
    "        else:\n",
    "\n",
    "            K_l = solver_left(x_left, K_left, q_entry, q_exit, delt, delx, fd_type, t, k_jam, v_free)\n",
    "            K_r = solver_right(x_right, K_right, q_entry, q_exit, delt, delx, fd_type, t, k_jam, v_free)\n",
    "            K  = np.hstack((K_l, K_r))\n",
    "\n",
    "        turning_point = compute_psi(K[t, :],x_ind)\n",
    "\n",
    "        x_left = np.where(x_ind <= turning_point)\n",
    "        x_right = np.where(x_ind > turning_point)\n",
    "    \n",
    "        K_left = K[:, x_left[0]]\n",
    "        K_right = K[:, x_right[0]]\n",
    "\n",
    "        if (np.abs(K[t,:]) < 1e-3).all():\n",
    "            return K, store_tp\n",
    "\n",
    "    return K, store_tp\n",
    "\n",
    "\n",
    "def step_func_gen(x_grid, kmax, num_steps, num_points, step_height_std):\n",
    "    # Continuously generate until the profile has exactly num_steps+1 unique values after rounding.\n",
    "    while True:\n",
    "        # Randomly select num_steps unique step positions (not including the start or end)\n",
    "        step_positions = np.sort(np.random.choice(range(1, num_points), size=num_steps, replace=False))\n",
    "        # Include the start and end of the grid as boundaries\n",
    "        boundaries = np.concatenate(([0], step_positions, [num_points]))\n",
    "        \n",
    "        # Generate density values for each segment.\n",
    "        # Start with an initial density chosen uniformly from 0.01 to 0.99.\n",
    "        densities = [np.random.uniform(0.05, 0.9)]\n",
    "        for _ in range(num_steps):\n",
    "            # Generate the next density from a normal distribution centered at the previous density\n",
    "            new_density = np.random.normal(densities[-1], step_height_std)\n",
    "            # Clip the new density to be within the desired range\n",
    "            new_density = np.clip(new_density, 0.05, 0.9)\n",
    "            densities.append(new_density)\n",
    "        \n",
    "        # Now assign each density value to the corresponding region defined by the boundaries.\n",
    "        k_initial = np.empty(num_points, dtype=float)\n",
    "        for i in range(len(densities)):\n",
    "            start = boundaries[i]\n",
    "            end = boundaries[i+1]\n",
    "            k_initial[start:end] = densities[i]\n",
    "        \n",
    "        # Round values to two decimals.\n",
    "        k_initial_rounded = np.round(k_initial, 2)\n",
    "        \n",
    "        # Verify that we have exactly num_steps+1 unique values after rounding.\n",
    "        if len(np.unique(k_initial_rounded)) == num_steps + 1:\n",
    "            return k_initial_rounded.astype('float')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c31313-dd87-4dad-b0af-e7fb51a64c4d",
   "metadata": {},
   "source": [
    "# code to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c976f-477a-4bc9-965c-06a85dc88f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(K):\n",
    "    # Create a deep copy of the list so as not to modify the original arrays.\n",
    "    train_x = [np.copy(arr) for arr in K]\n",
    "    # For every array except the first, set all elements to zero.\n",
    "    for i in range(1, len(train_x)):\n",
    "        train_x[i] = np.zeros_like(train_x[i])\n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc7c07-3027-4975-ba77-48d89b129dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# User-specified parameters:\n",
    "step_options = [1, 2, 3]  # List of num_steps values to generate (can be any integers)\n",
    "n_train = 800             # Number of training samples per step group\n",
    "n_val   = 200        # Number of validation samples per step group\n",
    "n_test  = 200        # Number of test samples per step group\n",
    "total_group = n_train + n_val + n_test  # Total samples for each step group\n",
    "# max_time_lim = 1400\n",
    "# min_time_value = 650\n",
    "downsample_factor_t = 36\n",
    "downsample_factor_x = 6\n",
    "tps_max = 450\n",
    "step_height_std = 0.45\n",
    "k_max = 1\n",
    "\n",
    "fd_params = {\n",
    "    \"k_jam\": 1,\n",
    "    \"v_free\": 1,\n",
    "    \"fd_type\": \"Greenshield\"\n",
    "}\n",
    "\n",
    "\n",
    "x_max = 2                  # road length in kilometres\n",
    "t_max = 3                   # time period of simulation in hours\n",
    "delx = 1/600                      # cell length in kilometres\n",
    "delt = 1/600                       # time discretization in hours\n",
    "x_nums = round(x_max/delx)\n",
    "t_nums = round(t_max/delt)\n",
    "\n",
    "q_entry = np.random.uniform(0,0, t_nums)\n",
    "q_exit = np.random.uniform(0,0, t_nums)\n",
    "k_jam_space = np.repeat(fd_params[\"k_jam\"], x_nums)\n",
    "\n",
    "x_ind = np.arange(0, x_nums)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Initialize a dictionary to hold only Y datasets for each step group and split.\n",
    "datasets = {}\n",
    "for steps in step_options:\n",
    "    datasets[steps] = {\n",
    "        'train': {'X': [], 'Y': []},\n",
    "        'val':   {'X': [], 'Y': []},\n",
    "        'test':  {'X': [], 'Y': []}\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Data Generation Loop:\n",
    "# For each step option, generate the required number of samples.\n",
    "for steps in step_options:\n",
    "    print(f\"Generating samples for {steps}-step data...\")\n",
    "    for local_index in range(total_group):\n",
    "        accepted_sample = False\n",
    "        # Continue trying until an acceptable sample is generated.\n",
    "        while not accepted_sample:\n",
    "            k_initial = step_func_gen(x_ind, k_max, steps, x_nums, step_height_std)\n",
    "\n",
    "            K, tps = simulation(k_initial, q_entry, q_exit,\n",
    "                               t_nums, x_nums, delt, delx, fd_params, k_jam_space)\n",
    "\n",
    "            \n",
    "            if (np.max(tps) - np.min(tps)) > tps_max:\n",
    "                print(f\"Step {steps} sample {local_index} discarded due to tps range > {tps_max}\")\n",
    "                continue\n",
    "                \n",
    "            # # Check if the number of time steps is within the desired range.\n",
    "            # if len(K) < min_time_value or len(K) > max_time_lim:\n",
    "            #     print(f\"Step {steps} sample {local_index} discarded due to time steps length {len(K)} outside [{min_time_value},{max_time_lim}]\")\n",
    "            #     continue\n",
    "\n",
    "            if not np.any(K[ :150,:] < 0.01):\n",
    "                print(f\"Step {steps} sample {local_index} discarded due to no K value < 0.01 for t < 120\")\n",
    "                continue\n",
    "\n",
    "            # Check if any array in K has values outside the range [0, 1]\n",
    "            if any(np.any(arr < 0) or np.any(arr > 1) for arr in K):\n",
    "                print(f\"Step {steps} sample {local_index} discarded due to K values outside [0, 1]\")\n",
    "                continue\n",
    "            accepted_sample = True\n",
    "\n",
    "        # Deep copy of K for storage.\n",
    "        K_copy = [np.copy(arr) for arr in K]\n",
    "        # Create a train version of K (first time step preserved, others zeroed).\n",
    "        train_x_data = create_train_data(K)\n",
    "        \n",
    "        # Assign the sample based on local_index.\n",
    "        if local_index < n_train:\n",
    "            datasets[steps]['train']['Y'].append(K_copy)\n",
    "            datasets[steps]['train']['X'].append(train_x_data)\n",
    "        elif local_index < n_train + n_val:\n",
    "            datasets[steps]['val']['Y'].append(K_copy)\n",
    "            datasets[steps]['val']['X'].append(train_x_data)\n",
    "        else:\n",
    "            datasets[steps]['test']['Y'].append(K_copy)\n",
    "            datasets[steps]['test']['X'].append(train_x_data)\n",
    "\n",
    "# ------------------------------\n",
    "# Padding: Ensure all samples have the same number of time steps.\n",
    "def pad_sample(sample, max_steps):\n",
    "    padded_sample = sample.copy()\n",
    "    current_steps = len(padded_sample)\n",
    "    if current_steps < max_steps:\n",
    "        pad_shape = padded_sample[0].shape  # assume same shape per time step\n",
    "        for _ in range(max_steps - current_steps):\n",
    "            padded_sample.append(np.zeros(pad_shape))\n",
    "    return padded_sample\n",
    "\n",
    "def pad_and_stack(dataset, max_steps):\n",
    "    new_dataset = []\n",
    "    for sample in dataset:\n",
    "        padded_sample = pad_sample(sample, max_steps)\n",
    "        sample_array = np.stack(padded_sample, axis=0)\n",
    "        new_dataset.append(sample_array)\n",
    "    return new_dataset\n",
    "\n",
    "# Determine maximum number of time steps across all datasets.\n",
    "all_samples = []\n",
    "for steps in step_options:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        all_samples.extend(datasets[steps][split]['Y'])\n",
    "        all_samples.extend(datasets[steps][split]['X'])\n",
    "if all_samples:\n",
    "    max_steps = max(len(sample) for sample in all_samples)\n",
    "else:\n",
    "    raise ValueError(\"No samples generated!\")\n",
    "print(\"Max time steps across all samples:\", max_steps)\n",
    "\n",
    "# Pad and stack every dataset.\n",
    "for steps in step_options:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        datasets[steps][split]['Y'] = pad_and_stack(datasets[steps][split]['Y'], max_steps)\n",
    "        datasets[steps][split]['X'] = pad_and_stack(datasets[steps][split]['X'], max_steps)\n",
    "\n",
    "# ------------------------------\n",
    "# Downsampling: For example, take every n-th time step.\n",
    "def downsample_dataset(dataset, n, m):\n",
    "    return [sample[::n, ::m] for sample in dataset]\n",
    "\n",
    "\n",
    "for steps in step_options:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        datasets[steps][split]['Y'] = downsample_dataset(datasets[steps][split]['Y'], downsample_factor_t, downsample_factor_x)\n",
    "        datasets[steps][split]['X'] = downsample_dataset(datasets[steps][split]['X'], downsample_factor_t, downsample_factor_x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284979c-f89f-4dd9-b256-66194e819ac9",
   "metadata": {},
   "source": [
    "# Plot Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6dd4f-096b-48fb-8d0d-6e2e060abaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select one sample from each step group from the training set.\n",
    "sample1 = datasets[1]['train']['Y'][1]\n",
    "sample2 = datasets[2]['train']['Y'][1]\n",
    "sample3 = datasets[3]['train']['Y'][1]\n",
    "\n",
    "# Create a figure with three subplots.\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 8))\n",
    "\n",
    "# Plot the first feature (column 0) of each sample.\n",
    "axs[0].plot(sample1[0, :])\n",
    "axs[0].set_title(\"1-Step Sample (TrainY) - Feature 0\")\n",
    "axs[0].set_xlabel(\"Time Step\")\n",
    "axs[0].set_ylabel(\"Value\")\n",
    "\n",
    "axs[1].plot(sample2[0, :])\n",
    "axs[1].set_title(\"2-Step Sample (TrainY) - Feature 0\")\n",
    "axs[1].set_xlabel(\"Time Step\")\n",
    "axs[1].set_ylabel(\"Value\")\n",
    "\n",
    "axs[2].plot(sample3[0, :])\n",
    "axs[2].set_title(\"3-Step Sample (TrainY) - Feature 0\")\n",
    "axs[2].set_xlabel(\"Time Step\")\n",
    "axs[2].set_ylabel(\"Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b162da-4b4d-436e-9ba6-f117b2e42d5f",
   "metadata": {},
   "source": [
    "# Plot random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1188e3-9cdb-4dd5-a3c4-3f428e436d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Select one random sample from each step group training set.\n",
    "random_sample1 = random.choice(datasets[1]['train']['Y'])\n",
    "random_sample2 = random.choice(datasets[2]['train']['Y'])\n",
    "random_sample3 = random.choice(datasets[3]['train']['Y'])\n",
    "\n",
    "# Create a figure with three subplots (one per step group).\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "vmin=0\n",
    "vmax=1\n",
    "\n",
    "# Plot 1-Step sample.\n",
    "im1 = axs[0].imshow(random_sample1, aspect='auto', origin='lower',  cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_title(\"Random 1-Step Sample (TrainY)\")\n",
    "axs[0].set_xlabel(\"x\")\n",
    "axs[0].set_ylabel(\"Time\")\n",
    "fig.colorbar(im1, ax=axs[0])\n",
    "\n",
    "# Plot 2-Step sample.\n",
    "im2 = axs[1].imshow(random_sample2, aspect='auto', origin='lower',  cmap='jet',vmin=vmin, vmax=vmax)\n",
    "axs[1].set_title(\"Random 2-Step Sample (TrainY)\")\n",
    "axs[1].set_xlabel(\"x\")\n",
    "axs[1].set_ylabel(\"Time\")\n",
    "fig.colorbar(im2, ax=axs[1])\n",
    "\n",
    "# Plot 3-Step sample.\n",
    "im3 = axs[2].imshow(random_sample3, aspect='auto', origin='lower', cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axs[2].set_title(\"Random 3-Step Sample (TrainY)\")\n",
    "axs[2].set_xlabel(\"x\")\n",
    "axs[2].set_ylabel(\"Time\")\n",
    "fig.colorbar(im3, ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321eea57-3c41-4f7e-b5c3-8a0209136a2a",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d6d97-802b-44dc-998d-8190f3da41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Use integer keys based on your datasets dictionary\n",
    "step_options = [1, 2, 3]\n",
    "splits = ['train', 'val', 'test']\n",
    "base_path = 'Godunov_easier_dataset//'\n",
    "\n",
    "for split in splits:\n",
    "    combined_X = []\n",
    "    combined_Y = []\n",
    "    for step in step_options:\n",
    "        # Directly access the data from your datasets dictionary using integer keys\n",
    "        data = datasets[step][split]\n",
    "        combined_X.append(data['X'])\n",
    "        combined_Y.append(data['Y'])\n",
    "    \n",
    "    # Concatenate arrays along the first axis (adjust axis if needed)\n",
    "    combined_X = np.concatenate(combined_X, axis=0)\n",
    "    combined_Y = np.concatenate(combined_Y, axis=0)\n",
    "    \n",
    "    # Create a dictionary for the combined data\n",
    "    combined_data = {'X': combined_X, 'Y': combined_Y}\n",
    "    \n",
    "    # Save the combined data as a .mat file\n",
    "    mat_filename = f'{base_path}combined_{split}_new.mat'\n",
    "    savemat(mat_filename, combined_data)\n",
    "    print(f\"Saved combined {split} data to {mat_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
